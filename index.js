import { Transform } from 'node:stream';
import mic from 'mic';
import fs from 'node:fs/promises';
import { tmpdir } from 'node:os';
import path from 'node:path';
import play from 'play-sound';
import { nodewhisper } from 'nodejs-whisper';
import { ChatOllama } from "@langchain/ollama";
import { createReactAgent } from "langchain/agents";
import { pull } from "langchain/hub";
import { AgentExecutor } from "langchain/agents";
import { DynamicTool } from "@langchain/core/tools";
import { exec } from 'node:child_process';
import { promisify } from 'node:util';
import axios from 'axios';
import FormData from 'form-data';

const execAsync = promisify(exec);

const SAMPLE_RATE = 16000;
const SILENCE_TIMEOUT = 2000;
const player = play({ players: ['mpg123'] });

// ÐšÐ°ÑÑ‚Ð¾Ð¼Ð½Ñ‹Ð¹ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð°Ð³ÐµÐ½Ñ‚Ð° (Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ°)
const customTool = new DynamicTool({
  name: "custom_search",
  description: "ÐŸÐ¾Ð¸ÑÐº Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ (Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ°)",
  func: async (input) => {
    return `Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð¾Ð¸ÑÐºÐ° Ð´Ð»Ñ "${input}": Ð—Ð´ÐµÑÑŒ Ð¼Ð¾Ð³Ð»Ð° Ð±Ñ‹Ñ‚ÑŒ Ð¿Ð¾Ð»ÐµÐ·Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ`;
  },
});

// Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ DeepSeek Ñ‡ÐµÑ€ÐµÐ· Ollama
const llm = new ChatOllama({
  model: "deepseek-r1:1.5b",
  baseUrl: "http://localhost:11434",
  temperature: 0.1,
});

let executor;

// ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð°Ð³ÐµÐ½Ñ‚Ð°
async function setupAgent() {
  const prompt = await pull("hwchase17/react");
  const agent = await createReactAgent({
    llm,
    tools: [customTool],
    prompt,
  });
  executor = AgentExecutor.fromAgentAndTools({
    agent,
    tools: [customTool],
    handleParsingErrors: true,
  });
}

// Ð”ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð³Ð¾Ð»Ð¾ÑÐ° (VAD)
function createVoiceDetector() {
  let silenceTimer = null;
  const vad = new Transform({
    transform(chunk, encoding, callback) {
      const energy = calculateEnergy(chunk);
      if (energy > 0.0005) {
        if (silenceTimer) clearTimeout(silenceTimer);
        silenceTimer = setTimeout(() => {
          vad.emit('silence');
        }, SILENCE_TIMEOUT);
      } else if (!silenceTimer) {
        silenceTimer = setTimeout(() => {
          vad.emit('silence');
        }, SILENCE_TIMEOUT);
      }
      this.push(chunk);
      callback();
    }
  });

  function calculateEnergy(chunk) {
    let energy = 0;
    for (let i = 0; i < chunk.length; i += 2) {
      energy += Math.abs(chunk.readInt16LE(i));
    }
    return energy / (chunk.length / 2) / 32767;
  }

  return vad;
}

// Ð¡Ð»ÑƒÑˆÐ°ÐµÐ¼ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½
async function listen() {
  return new Promise((resolve, reject) => {
    const micInstance = mic({
      rate: String(SAMPLE_RATE),
      channels: '1',
      device: 'default',
      format: 'S16_LE',
      debug: false,
      exitOnSilence: 0
    });

    const audioChunks = [];
    const vad = createVoiceDetector();
    const audioStream = micInstance.getAudioStream();

    audioStream
      .pipe(vad)
      .on('data', chunk => {
        audioChunks.push(chunk);
      })
      .on('error', reject);

    vad.on('silence', () => {
      micInstance.stop();
    });

    audioStream
      .on('startComplete', () => console.log('ðŸŽ¤ Ð¡Ð»ÑƒÑˆÐ°ÑŽ...'))
      .on('stopComplete', () => {
        resolve(Buffer.concat(audioChunks));
      });

    const timeout = setTimeout(() => {
      micInstance.stop();
      reject(new Error('Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð·Ð°Ð¿Ð¸ÑÐ¸'));
    }, 30000);

    micInstance.start();

    audioStream.on('stopComplete', () => clearTimeout(timeout));
  });
}

// ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ Ð°ÑƒÐ´Ð¸Ð¾ Ð² WAV
async function convertToWav(audioBufferOrPath) {
  const tempOutputFile = path.join(process.cwd(), `converted_${Date.now()}.wav`);
  let ffmpegCommand;

  if (typeof audioBufferOrPath === 'string') {
    ffmpegCommand = `ffmpeg -i "${audioBufferOrPath}" -ar 16000 -ac 1 -f wav "${tempOutputFile}" -y`;
  } else {
    const tempInputFile = path.join(process.cwd(), `raw_${Date.now()}.pcm`);
    await fs.writeFile(tempInputFile, audioBufferOrPath);
    ffmpegCommand = `ffmpeg -f s16le -ar ${SAMPLE_RATE} -ac 1 -i "${tempInputFile}" -ar 16000 -ac 1 -f wav "${tempOutputFile}" -y`;
    await execAsync(ffmpegCommand);
    await fs.unlink(tempInputFile);
    return tempOutputFile;
  }

  await execAsync(ffmpegCommand);
  return tempOutputFile;
}

// Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ð°ÑƒÐ´Ð¸Ð¾ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Whisper
async function transcribe(audioBufferOrPath) {
  const wavFile = await convertToWav(audioBufferOrPath);
  const textFile = `${wavFile}.txt`; // Ð¤Ð°Ð¹Ð», ÐºÑƒÐ´Ð° Whisper ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
  try {
    const result = await nodewhisper(wavFile, {
      modelName: 'base',
      autoDownloadModelName: 'base',
      removeWavFileAfterTranscription: true,
      whisperOptions: {
        outputInText: true,
        language: 'ru',
      },
    });
    if (result.text) {
      return result.text;
    }
    const transcribedText = await fs.readFile(textFile, 'utf8');
    return transcribedText.trim() || "ÐžÑˆÐ¸Ð±ÐºÐ°: Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð°ÑÑŒ";
  } catch (err) {
    console.error('ÐžÑˆÐ¸Ð±ÐºÐ° Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸:', err);
    return "ÐžÑˆÐ¸Ð±ÐºÐ°: Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð°ÑÑŒ";
  } finally {
    await fs.unlink(textFile).catch(() => {});
  }
}

// ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ð°Ð³ÐµÐ½Ñ‚Ð° DeepSeek
async function brainAppeal(text) {
  if (!text || text === "ÐžÑˆÐ¸Ð±ÐºÐ°: Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð°ÑÑŒ") {
    return "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ Ñ€ÐµÑ‡ÑŒ.";
  }

  console.log('Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚...');
  const prompt = [
    { role: "system", content: "ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ, Ð±ÐµÐ· Ð»Ð¸ÑˆÐ½Ð¸Ñ… Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹." },
    { role: "user", content: text }
  ];
  const response = await llm.invoke(prompt);
  return response.content;
}

// Ð¡Ð¸Ð½Ñ‚ÐµÐ· Ð¸ Ð²Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ñ‡ÐµÑ€ÐµÐ· Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ TTS-ÑÐµÑ€Ð²ÐµÑ€
async function voice(text) {
  const form = new FormData();
  form.append('text', text);
  form.append('reference_audio_path', 'reference.wav'); // Ð¤Ð°Ð¹Ð» Ñ Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð¾Ð¼ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ°

  try {
    const response = await axios.post('http://localhost:5000/tts', form, {
      headers: form.getHeaders(),
      responseType: 'arraybuffer'
    });
    const buffer = Buffer.from(response.data);
    const outputFile = path.join(process.cwd(), `response_${Date.now()}.wav`); // Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð² Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸
    await fs.writeFile(outputFile, buffer);

    await new Promise((resolve, reject) => {
      player.play(outputFile, (err) => err ? reject(err) : resolve());
    });

    console.log(`ÐÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð» ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½: ${outputFile}`);
    // Ð¤Ð°Ð¹Ð» Ð½Ðµ ÑƒÐ´Ð°Ð»ÑÐµÑ‚ÑÑ
  } catch (error) {
    console.error('ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÑ‡Ð¸:', error.message);
  }
}

// ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ†Ð¸ÐºÐ»
async function mainLoop() {
  await setupAgent();
  while (true) {
    try {
      // Ð”Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð² Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ
      // const audio = "/workspace/InnerEcho/test/audio_2025-02-22_09-29-56.wav"; // Ð—Ð°Ð¼ÐµÐ½Ð¸Ñ‚Ðµ Ð½Ð° Ð²Ð°Ñˆ Ñ„Ð°Ð¹Ð»
      const audio = await listen(); // Ð Ð°ÑÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð´Ð»Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð·Ð°Ð¿Ð¸ÑÐ¸
      const text = await transcribe(audio);
      console.log('Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ:', text);
      const response = await brainAppeal(text);
      console.log('ÐžÑ‚Ð²ÐµÑ‚ AI:', response);
      await voice(response);
      await new Promise(resolve => setTimeout(resolve, 500));
    } catch (err) {
      console.error('ÐžÑˆÐ¸Ð±ÐºÐ° Ð² Ð³Ð»Ð°Ð²Ð½Ð¾Ð¼ Ñ†Ð¸ÐºÐ»Ðµ:', err);
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }
}

mainLoop().catch(console.error);